{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ee1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare dataset\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = len(np.unique(y_train))\n",
    "input_shape = x_train.shape[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce0f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare data for siamese network\n",
    "def prepare_dataset(x, y, n=num_classes):\n",
    "    # Select 10 samples for each class\n",
    "    classes = np.unique(y_train)\n",
    "    cls_dict = dict()\n",
    "    for cls in classes:\n",
    "        cls_idx = np.argwhere(y_train == cls).reshape(-1, )\n",
    "        cls_idx = np.random.choice(cls_idx, n)\n",
    "        cls_dict[cls] = cls_idx\n",
    "\n",
    "    x_pos = list()\n",
    "    x_neg = list()\n",
    "    for cls in classes:\n",
    "        a = x_train[cls_dict[cls][0]]\n",
    "\n",
    "        # Positive samples\n",
    "        for idx, elem in enumerate(cls_dict[cls]):\n",
    "            if idx > 0:\n",
    "                b = x_train[elem]\n",
    "                x_pos.append((a, b))\n",
    "\n",
    "        # Negative samples\n",
    "        for temp in classes:\n",
    "            if temp == cls:\n",
    "                continue\n",
    "\n",
    "            random_idx = np.random.choice(cls_dict[temp], int(num_classes/n))\n",
    "            b = np.squeeze(x_train[random_idx], axis=0)\n",
    "            x_neg.append((a, b))\n",
    "\n",
    "    x_pos_arr = np.array(x_pos)\n",
    "    x_neg_arr = np.array(x_neg)\n",
    "    y_pos = np.ones(shape=len(x_pos_arr))\n",
    "    y_neg = np.zeros(shape=len(x_neg_arr))\n",
    "\n",
    "    siam_inputs = np.append(x_pos_arr, x_neg_arr, axis=0)\n",
    "    siam_labels = np.append(y_pos, y_neg)\n",
    "\n",
    "    # Shuffle\n",
    "    shuffle_idx = np.arange(len(siam_inputs))\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    siam_inputs = siam_inputs[shuffle_idx]\n",
    "    siam_labels = siam_labels[shuffle_idx].astype(np.int32)\n",
    "    \n",
    "    return siam_inputs, siam_labels\n",
    "\n",
    "siam_inputs, siam_labels = prepare_dataset(x_train, y_train, n=10)\n",
    "siam_inputs_v, siam_labels_v = prepare_dataset(x_test, y_test, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaeb870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a81a4bbdf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IDX = np.random.randint(0, len(siam_labels))\n",
    "print(siam_labels[IDX])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(siam_inputs[IDX, 0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(siam_inputs[IDX, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b830ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 5s 8ms/step - loss: 2.7111 - accuracy: 0.3468 - val_loss: 0.7660 - val_accuracy: 0.7791\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.9588 - accuracy: 0.6918 - val_loss: 0.3398 - val_accuracy: 0.9144\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.6316 - accuracy: 0.8073 - val_loss: 0.2392 - val_accuracy: 0.9406\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4866 - accuracy: 0.8571 - val_loss: 0.1846 - val_accuracy: 0.9519\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3946 - accuracy: 0.8830 - val_loss: 0.1504 - val_accuracy: 0.9601\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3363 - accuracy: 0.9004 - val_loss: 0.1273 - val_accuracy: 0.9629\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3011 - accuracy: 0.9090 - val_loss: 0.1202 - val_accuracy: 0.9676\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.2707 - accuracy: 0.9200 - val_loss: 0.1069 - val_accuracy: 0.9715\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2471 - accuracy: 0.9256 - val_loss: 0.0923 - val_accuracy: 0.9745\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2237 - accuracy: 0.9333 - val_loss: 0.0889 - val_accuracy: 0.9746\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2142 - accuracy: 0.9367 - val_loss: 0.0804 - val_accuracy: 0.9784\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1933 - accuracy: 0.9435 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1817 - accuracy: 0.9469 - val_loss: 0.0774 - val_accuracy: 0.9774\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1689 - accuracy: 0.9512 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1589 - accuracy: 0.9542 - val_loss: 0.0694 - val_accuracy: 0.9797\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.9585 - val_loss: 0.0721 - val_accuracy: 0.9805\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1450 - accuracy: 0.9597 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.9614 - val_loss: 0.0662 - val_accuracy: 0.9817\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1271 - accuracy: 0.9629 - val_loss: 0.0613 - val_accuracy: 0.9847\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1243 - accuracy: 0.9654 - val_loss: 0.0605 - val_accuracy: 0.9837\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9672 - val_loss: 0.0615 - val_accuracy: 0.9841\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.9666 - val_loss: 0.0607 - val_accuracy: 0.9844\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9693 - val_loss: 0.0533 - val_accuracy: 0.9841\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1039 - accuracy: 0.9702 - val_loss: 0.0574 - val_accuracy: 0.9848\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1013 - accuracy: 0.9711 - val_loss: 0.0544 - val_accuracy: 0.9852\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1013 - accuracy: 0.9715 - val_loss: 0.0541 - val_accuracy: 0.9851\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0957 - accuracy: 0.9725 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0939 - accuracy: 0.9730 - val_loss: 0.0552 - val_accuracy: 0.9844\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                9280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 17,008\n",
      "Trainable params: 0\n",
      "Non-trainable params: 17,008\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#%% Create model for extracting feature vector\n",
    "def create_embedding(embedding_size):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape)(inputs)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(embedding_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(embedding_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedding\")\n",
    "    \n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='Adam',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    #%% Train embedding model\n",
    "    batch_size = 256\n",
    "    epochs = 50\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train, \n",
    "                        y_train, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        callbacks=[earlystop],\n",
    "                        use_multiprocessing=True,\n",
    "                        verbose=True,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Extract pretrained model for embedding\n",
    "    emb_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)\n",
    "    for layer in emb_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return emb_model\n",
    "\n",
    "embedding = create_embedding(embedding_size=64)\n",
    "print(embedding.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b0dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive embedding distance: 6.711926460266113\n",
      "Negative embedding distance: 49.85800552368164\n"
     ]
    }
   ],
   "source": [
    "#%% Embedding test\n",
    "# Get some samples with label 7\n",
    "idx7 = np.argwhere(y_test == 7)[:5].reshape(-1, )\n",
    "emb_idx7 = embedding.predict(x_test[idx7])\n",
    "\n",
    "idx8 = np.argwhere(y_test == 8)[:5].reshape(-1, )\n",
    "emb_idx8 = embedding.predict(x_test[idx8])\n",
    "\n",
    "# Positive example\n",
    "dp = np.sqrt(np.sum(np.square(emb_idx7[0] - emb_idx7[3])))\n",
    "print(\"Positive embedding distance: {}\".format(dp))\n",
    "\n",
    "# Negative example\n",
    "dn = np.sqrt(np.sum(np.square(emb_idx7[0] - emb_idx8[3])))\n",
    "print(\"Negative embedding distance: {}\".format(dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb054ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"siamese\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 64)           17008       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 64)           0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 64)           0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (1, 1)               0           tf.math.square[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sqrt (TFOpLambda)       (1, 1)               0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (1, 1)               0           tf.math.sqrt[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (1, 1)               2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,010\n",
      "Trainable params: 2\n",
      "Non-trainable params: 17,008\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#%% Create Siamese model\n",
    "input_image = tf.keras.Input(shape=input_shape)\n",
    "ref_image = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "input_emb = embedding(input_image)\n",
    "ref_emb = embedding(ref_image)\n",
    "\n",
    "distance = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(input_emb - ref_emb), keepdims=True))\n",
    "distance = tf.keras.layers.Lambda(lambda x: x / 1000)(distance)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "siamese = tf.keras.Model(inputs=[input_image, ref_image], outputs=outputs, name=\"siamese\")\n",
    "\n",
    "siamese.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(siamese.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1c09d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.6995 - accuracy: 0.5000 - val_loss: 0.7053 - val_accuracy: 0.4778\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.7012 - accuracy: 0.4778 - val_loss: 0.7048 - val_accuracy: 0.4056\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6996 - accuracy: 0.4889 - val_loss: 0.7045 - val_accuracy: 0.3722\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6989 - accuracy: 0.4778 - val_loss: 0.7042 - val_accuracy: 0.3167\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6994 - accuracy: 0.4944 - val_loss: 0.7038 - val_accuracy: 0.1611\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.7000 - accuracy: 0.3444 - val_loss: 0.7034 - val_accuracy: 0.1333\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6987 - accuracy: 0.3778 - val_loss: 0.7030 - val_accuracy: 0.1111\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6986 - accuracy: 0.4667 - val_loss: 0.7027 - val_accuracy: 0.0833\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6984 - accuracy: 0.3611 - val_loss: 0.7024 - val_accuracy: 0.0667\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6984 - accuracy: 0.3389 - val_loss: 0.7020 - val_accuracy: 0.0444\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6979 - accuracy: 0.3667 - val_loss: 0.7017 - val_accuracy: 0.0444\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6986 - accuracy: 0.3667 - val_loss: 0.7013 - val_accuracy: 0.0500\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6982 - accuracy: 0.3000 - val_loss: 0.7010 - val_accuracy: 0.0611\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6979 - accuracy: 0.2889 - val_loss: 0.7006 - val_accuracy: 0.0500\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6970 - accuracy: 0.2722 - val_loss: 0.7003 - val_accuracy: 0.1278\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6972 - accuracy: 0.2611 - val_loss: 0.7000 - val_accuracy: 0.2278\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6977 - accuracy: 0.2056 - val_loss: 0.6996 - val_accuracy: 0.2222\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.2056 - val_loss: 0.6993 - val_accuracy: 0.2222\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6963 - accuracy: 0.2333 - val_loss: 0.6990 - val_accuracy: 0.2889\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.2722 - val_loss: 0.6987 - val_accuracy: 0.2500\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6966 - accuracy: 0.3556 - val_loss: 0.6984 - val_accuracy: 0.3056\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.2444 - val_loss: 0.6981 - val_accuracy: 0.3056\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6960 - accuracy: 0.2667 - val_loss: 0.6977 - val_accuracy: 0.4500\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6958 - accuracy: 0.2944 - val_loss: 0.6974 - val_accuracy: 0.4278\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6953 - accuracy: 0.4278 - val_loss: 0.6971 - val_accuracy: 0.4889\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6957 - accuracy: 0.2722 - val_loss: 0.6969 - val_accuracy: 0.3278\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6954 - accuracy: 0.4333 - val_loss: 0.6965 - val_accuracy: 0.4611\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6952 - accuracy: 0.4444 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.4833 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6949 - accuracy: 0.4667 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6944 - accuracy: 0.4722 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6945 - accuracy: 0.4167 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6943 - accuracy: 0.4833 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6942 - accuracy: 0.4611 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.5111 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6921 - accuracy: 0.5056 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6923 - accuracy: 0.5056 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6918 - accuracy: 0.5111 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6914 - accuracy: 0.6556 - val_loss: 0.6899 - val_accuracy: 0.5667\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6914 - accuracy: 0.5222 - val_loss: 0.6893 - val_accuracy: 0.5778\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6915 - accuracy: 0.5111 - val_loss: 0.6890 - val_accuracy: 0.5556\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6914 - accuracy: 0.5444 - val_loss: 0.6888 - val_accuracy: 0.8556\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6913 - accuracy: 0.5333 - val_loss: 0.6885 - val_accuracy: 0.8611\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6908 - accuracy: 0.5444 - val_loss: 0.6882 - val_accuracy: 0.7389\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.5444 - val_loss: 0.6879 - val_accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6905 - accuracy: 0.5333 - val_loss: 0.6876 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6902 - accuracy: 0.5444 - val_loss: 0.6873 - val_accuracy: 0.8611\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6898 - accuracy: 0.5333 - val_loss: 0.6870 - val_accuracy: 0.8611\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6897 - accuracy: 0.5389 - val_loss: 0.6867 - val_accuracy: 0.9111\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6896 - accuracy: 0.5111 - val_loss: 0.6863 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6898 - accuracy: 0.5667 - val_loss: 0.6860 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6895 - accuracy: 0.5667 - val_loss: 0.6857 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6894 - accuracy: 0.6000 - val_loss: 0.6855 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6891 - accuracy: 0.6333 - val_loss: 0.6852 - val_accuracy: 0.9556\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6888 - accuracy: 0.6056 - val_loss: 0.6849 - val_accuracy: 0.9556\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6891 - accuracy: 0.5944 - val_loss: 0.6845 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.6722 - val_loss: 0.6842 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6885 - accuracy: 0.6056 - val_loss: 0.6839 - val_accuracy: 0.9556\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6882 - accuracy: 0.6778 - val_loss: 0.6836 - val_accuracy: 0.9556\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6882 - accuracy: 0.7500 - val_loss: 0.6833 - val_accuracy: 0.9556\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6878 - accuracy: 0.6333 - val_loss: 0.6830 - val_accuracy: 0.9556\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6882 - accuracy: 0.7000 - val_loss: 0.6827 - val_accuracy: 0.9556\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6872 - accuracy: 0.5444 - val_loss: 0.6824 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6870 - accuracy: 0.6833 - val_loss: 0.6821 - val_accuracy: 0.9556\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.7278 - val_loss: 0.6817 - val_accuracy: 0.9611\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6865 - accuracy: 0.6778 - val_loss: 0.6814 - val_accuracy: 0.9556\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.6667 - val_loss: 0.6811 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6865 - accuracy: 0.6889 - val_loss: 0.6808 - val_accuracy: 0.9556\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.6444 - val_loss: 0.6806 - val_accuracy: 0.9611\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6867 - accuracy: 0.6556 - val_loss: 0.6803 - val_accuracy: 0.9611\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6858 - accuracy: 0.7111 - val_loss: 0.6799 - val_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6862 - accuracy: 0.6722 - val_loss: 0.6797 - val_accuracy: 0.9556\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6853 - accuracy: 0.7111 - val_loss: 0.6793 - val_accuracy: 0.9556\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6850 - accuracy: 0.7167 - val_loss: 0.6790 - val_accuracy: 0.9667\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.6278 - val_loss: 0.6787 - val_accuracy: 0.9556\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.7056 - val_loss: 0.6784 - val_accuracy: 0.9556\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6856 - accuracy: 0.6778 - val_loss: 0.6782 - val_accuracy: 0.9611\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6849 - accuracy: 0.7444 - val_loss: 0.6779 - val_accuracy: 0.9556\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6856 - accuracy: 0.6889 - val_loss: 0.6776 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6848 - accuracy: 0.6833 - val_loss: 0.6773 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6843 - accuracy: 0.7167 - val_loss: 0.6770 - val_accuracy: 0.9556\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6853 - accuracy: 0.6722 - val_loss: 0.6767 - val_accuracy: 0.9556\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.7278 - val_loss: 0.6764 - val_accuracy: 0.9389\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6824 - accuracy: 0.7833 - val_loss: 0.6761 - val_accuracy: 0.9389\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6850 - accuracy: 0.6944 - val_loss: 0.6758 - val_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6840 - accuracy: 0.6889 - val_loss: 0.6755 - val_accuracy: 0.9556\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.6556 - val_loss: 0.6752 - val_accuracy: 0.9389\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6836 - accuracy: 0.6944 - val_loss: 0.6749 - val_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.6827 - accuracy: 0.7333 - val_loss: 0.6747 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "#%% Training\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = siamese.fit([siam_inputs[:, 0], siam_inputs[:, 1]], \n",
    "                    siam_labels, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=[earlystop],\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=([siam_inputs_v[:, 0], siam_inputs_v[:, 1]], siam_labels_v),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f8b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-> For (8, 1), validation is False\n",
      "<+> For (8, 8), validation is True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def isSame(siamese, labels: tuple):\n",
    "    input_val = labels[0]\n",
    "    ref_val = labels[1]\n",
    "    \n",
    "    # Select random sample from test case\n",
    "    input_val_idx = np.argwhere(y_test == input_val).reshape(-1, )\n",
    "    input_val_idx = np.random.choice(input_val_idx, 1)\n",
    "    ref_val_idx = np.argwhere(y_test == ref_val).reshape(-1, )\n",
    "    ref_val_idx = np.random.choice(ref_val_idx, 1)\n",
    "    \n",
    "    # Predict\n",
    "    input_image = x_test[input_val_idx]\n",
    "    ref_image = x_test[ref_val_idx]\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(np.squeeze(input_image))\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(np.squeeze(ref_image))\n",
    "    prediction = siamese.predict([input_image, ref_image])\n",
    "    return (prediction > 0.5).item()\n",
    "\n",
    "vals = (np.random.randint(0, 10), np.random.randint(0, 10))\n",
    "print(\"<-> For {}, validation is {}\".format(vals, isSame(siamese, vals)))\n",
    "\n",
    "a = np.random.randint(0, 10)\n",
    "vals = (a, a)\n",
    "print(\"<+> For {}, validation is {}\".format(vals, isSame(siamese, vals)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
